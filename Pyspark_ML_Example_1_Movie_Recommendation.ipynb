{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collabrative Filtering Algorithm Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, LongType\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import sys\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"ALSExample\").getOrCreate()\n",
    "    \n",
    "moviesSchema = StructType([ \\\n",
    "                     StructField(\"userID\", IntegerType(), True), \\\n",
    "                     StructField(\"movieID\", IntegerType(), True), \\\n",
    "                     StructField(\"rating\", IntegerType(), True), \\\n",
    "                     StructField(\"timestamp\", LongType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadMovieNames():\n",
    "    movieNames = {}\n",
    "    # CHANGE THIS TO THE PATH TO YOUR u.ITEM FILE:\n",
    "    with codecs.open(\"ml-100k/u.ITEM\", \"r\", encoding='ISO-8859-1', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            fields = line.split('|')\n",
    "            movieNames[int(fields[0])] = fields[1]\n",
    "    return movieNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userID|movieID|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     0|    133|     1|881250949|\n",
      "|     0|     50|     5|881250949|\n",
      "|     0|    172|     5|881250949|\n",
      "|   196|    242|     3|881250949|\n",
      "|   186|    302|     3|891717742|\n",
      "|    22|    377|     1|878887116|\n",
      "|   244|     51|     2|880606923|\n",
      "|   166|    346|     1|886397596|\n",
      "|   298|    474|     4|884182806|\n",
      "|   115|    265|     2|881171488|\n",
      "|   253|    465|     5|891628467|\n",
      "|   305|    451|     3|886324817|\n",
      "|     6|     86|     3|883603013|\n",
      "|    62|    257|     2|879372434|\n",
      "|   286|   1014|     5|879781125|\n",
      "|   200|    222|     5|876042340|\n",
      "|   210|     40|     3|891035994|\n",
      "|   224|     29|     3|888104457|\n",
      "|   303|    785|     3|879485318|\n",
      "|   122|    387|     5|879270459|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = loadMovieNames()\n",
    "    \n",
    "ratings = spark.read.option(\"sep\", \"\\t\").schema(moviesSchema) \\\n",
    "    .csv(\"ml-100k/u.data\")\n",
    "    \n",
    "ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training recommendation model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ALSModel: uid=ALS_1662081da2d1, rank=10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training recommendation model...\")\n",
    "\n",
    "als = ALS().setMaxIter(5).setRegParam(0.01).setUserCol(\"userID\").setItemCol(\"movieID\") \\\n",
    "    .setRatingCol(\"rating\")\n",
    "    \n",
    "model = als.fit(ratings)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 recommendations for user ID 0\n",
      "Kicking and Screaming (1995)8.128525733947754\n",
      "Shall We Dance? (1937)8.030218124389648\n",
      "Crooklyn (1994)7.691278457641602\n",
      "Love in the Afternoon (1957)7.023828029632568\n",
      "Hearts and Minds (1996)6.709479331970215\n",
      "Truman Show, The (1998)6.520021438598633\n",
      "Man in the Iron Mask, The (1998)6.430258750915527\n",
      "Angel Baby (1995)6.333723068237305\n",
      "Chairman of the Board (1998)6.140254497528076\n",
      "Lost in Space (1998)6.133683204650879\n"
     ]
    }
   ],
   "source": [
    "# Manually construct a dataframe of the user ID's we want recs for\n",
    "userID = int(0)\n",
    "userSchema = StructType([StructField(\"userID\", IntegerType(), True)])\n",
    "users = spark.createDataFrame([[userID,]], userSchema)\n",
    "\n",
    "recommendations = model.recommendForUserSubset(users, 10).collect()\n",
    "\n",
    "print(\"Top 10 recommendations for user ID \" + str(userID))\n",
    "for userRecs in recommendations:\n",
    "    myRecs = userRecs[1]  #userRecs is (userID, [Row(movieId, rating), Row(movieID, rating)...])\n",
    "    for rec in myRecs: #my Recs is just the column of recs for the user\n",
    "        movie = rec[0] #For each rec in the list, extract the movie ID and rating\n",
    "        rating = rec[1]\n",
    "        movieName = names[movie]\n",
    "        print(movieName + str(rating))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
